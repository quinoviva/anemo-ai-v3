{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anemo AI: Enhanced Anemia Detection Training (EfficientNetB0)\n",
    "\n",
    "This notebook provides an upgraded pipeline for anemia detection using **EfficientNetB0** and **CLAHE** (Contrast Limited Adaptive Histogram Equalization) to improve accuracy and consistency across skin, fingernail, and conjunctiva images.\n",
    "\n",
    "### Key Enhancements:\n",
    "- **EfficientNetB0**: Superior feature extraction compared to MobileNet.\n",
    "- **CLAHE Preprocessing**: Enhances microvascular patterns and subtle color shifts.\n",
    "- **Swish Activation**: Default EfficientNet activation for better gradient flow.\n",
    "- **Advanced Explainability**: Optimized Grad-CAM for the EfficientNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"OpenCV: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Hyperparameters optimized for EfficientNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")) \n",
    "DATASET_PATH = os.path.join(BASE_DIR, 'dataset')\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 16\n",
    "PHASE1_EPOCHS = 25\n",
    "PHASE2_EPOCHS = 40\n",
    "LEARNING_RATE_P1 = 1e-3\n",
    "LEARNING_RATE_P2 = 1e-5\n",
    "\n",
    "DATASET_TYPES = ['skin', 'fingernails', 'conjunctiva']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Preprocessing (CLAHE)\n",
    "Applying CLAHE to highlight vital diagnostic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(img):\n",
    "    img = img.astype(np.uint8)\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "    return final.astype(np.float32)\n",
    "\n",
    "def custom_preprocessing(img):\n",
    "    # CLAHE + EfficientNet Scaling\n",
    "    img_clahe = apply_clahe(img)\n",
    "    return tf.keras.applications.efficientnet.preprocess_input(img_clahe)\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    img = load_img(img_path, target_size=size)\n",
    "    array = img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM explainability\n",
    "Visualizing where the AI focuses its attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name=\"top_activation\"):\n",
    "    grad_model = Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        class_channel = preds[:, 0]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, alpha=0.5, title=None):\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = img_to_array(jet_heatmap)\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(superimposed_img)\n",
    "    if title: plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Model Architecture\n",
    "Utilizing EfficientNetB0 with custom top layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_model():\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet', \n",
    "        include_top=False, \n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='swish')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='swish')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_P1),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Two-phase training: Head training followed by full fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_anemia_model(dataset_type):\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\" TRAINING ENHANCED: {dataset_type.upper()} \")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    target_path = os.path.join(DATASET_PATH, dataset_type)\n",
    "    if not os.path.exists(target_path): return\n",
    "\n",
    "    # 1. DATA AUGMENTATION\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=custom_preprocessing,\n",
    "        rotation_range=30, width_shift_range=0.2, height_shift_range=0.2,\n",
    "        zoom_range=0.2, horizontal_flip=True, brightness_range=[0.7, 1.3],\n",
    "        fill_mode='reflect', validation_split=0.2\n",
    "    )\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=custom_preprocessing, validation_split=0.2)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(target_path, 'train'),\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE,\n",
    "        class_mode='binary', subset='training'\n",
    "    )\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(target_path, 'train'),\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE,\n",
    "        class_mode='binary', subset='validation'\n",
    "    )\n",
    "\n",
    "    # Calculate Class Weights\n",
    "    classes = train_generator.classes\n",
    "    weights = class_weight.compute_class_weight('balanced', classes=np.unique(classes), y=classes)\n",
    "    class_weights = dict(enumerate(weights))\n",
    "\n",
    "    # 2. MODEL PREPARATION\n",
    "    model, base_model = create_advanced_model()\n",
    "    \n",
    "    callbacks = [\n",
    "        ModelCheckpoint(f\"anemia_{dataset_type}_efficientnet.h5\", save_best_only=True, monitor='val_auc', mode='max'),\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-8),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # 3. PHASE 1\n",
    "    print(\"\\n[Phase 1] Training classification layers...\")\n",
    "    model.fit(train_generator, epochs=PHASE1_EPOCHS, validation_data=validation_generator, callbacks=callbacks, class_weight=class_weights)\n",
    "\n",
    "    # 4. PHASE 2\n",
    "    print(\"\\n[Phase 2] Fine-tuning all layers...\")\n",
    "    base_model.trainable = True\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE_P2), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "    model.fit(train_generator, epochs=PHASE2_EPOCHS, validation_data=validation_generator, callbacks=callbacks, class_weight=class_weights)\n",
    "\n",
    "    # 5. SAMPLE VISUALIZATION\n",
    "    test_dir = os.path.join(target_path, 'test')\n",
    "    if os.path.exists(test_dir):\n",
    "        all_imgs = []\n",
    "        for r, d, f in os.walk(test_dir):\n",
    "            for file in f: \n",
    "                if file.lower().endswith(('.png', '.jpg')): all_imgs.append(os.path.join(r, file))\n",
    "        \n",
    "        if all_imgs:\n",
    "            sample = random.choice(all_imgs)\n",
    "            img_array = custom_preprocessing(get_img_array(sample, (IMG_HEIGHT, IMG_WIDTH)))\n",
    "            pred = model.predict(img_array)[0][0]\n",
    "            heatmap = make_gradcam_heatmap(img_array, model)\n",
    "            save_and_display_gradcam(sample, heatmap, title=f\"Result: {'Anemic' if pred > 0.5 else 'Healthy'} ({pred:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in DATASET_TYPES:\n",
    "    train_anemia_model(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
